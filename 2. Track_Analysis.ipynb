{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Track Analysis\n",
    "\n",
    "In order to properly analyze our GPX tracks, we need to put all of them into the same _frame-of-reference_.   This is accomplished by the following.\n",
    "\n",
    "* Given a starting point and ending point, we can determine the best route through the  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = 'bike_data.db'\n",
    "\n",
    "start_coord = (39.5989743, -104.8609468)\n",
    "end_coord   = (39.75428108249532, -105.00085402872664)\n",
    "\n",
    "dist_thresh_m = 20\n",
    "step_dist_m = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from ipyleaflet import Map, Marker, Polygon, Polyline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import math, cmath\n",
    "from geographiclib.geodesic import Geodesic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy connectable \n",
    "conn = create_engine( 'sqlite:///' + database_path ).connect()\n",
    "\n",
    "#  For each segment, we need to create a track for each dataset\n",
    "dataset_ids = pd.read_sql_query('SELECT DISTINCT dataset_id FROM point_list', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  For each dataset, load the points w.r.t. each dataset-id, sorted by time.\n",
    "points_by_dataset = {}\n",
    "for dataset_id in dataset_ids['dataset_id']:\n",
    "        \n",
    "    #  Create a full track of the segment\n",
    "    sql_query = 'SELECT * FROM point_list WHERE dataset_id = {} ORDER BY timestamp'.format( dataset_id )\n",
    "    points_by_dataset[dataset_id] = { 'points': pd.read_sql_query( sql_query, conn ) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compute Initial Starting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-443f5a5061ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtemp_angles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         current_point = ( points_by_dataset[dataset_id]['points']['latitude'][current_idx[dataset_idx]],\n\u001b[0m\u001b[1;32m     20\u001b[0m                           points_by_dataset[dataset_id]['points']['longitude'][current_idx[dataset_idx]] )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_idx' is not defined"
     ]
    }
   ],
   "source": [
    "def mean_angle(angles):\n",
    "    return math.degrees(cmath.phase(sum(cmath.rect(1, math.radians(d)) for d in angles)/len(angles)))\n",
    "\n",
    "waypoint_list = []\n",
    "current_point = start_coord\n",
    "matching_points = []\n",
    "\n",
    "current_idx = {}\n",
    "for dataset_id in dataset_ids['dataset_id']:\n",
    "    current_idx[dataset_id] = 0\n",
    "\n",
    "\n",
    "#  Start a loop, running until all points are complete\n",
    "while True:\n",
    "    \n",
    "    #  Look for the nearest first points within the threshold\n",
    "    temp_angles = []\n",
    "    for dataset_id in dataset_ids['dataset_id']:\n",
    "        current_point = ( points_by_dataset[dataset_id]['points']['latitude'][current_idx[dataset_idx]],\n",
    "                          points_by_dataset[dataset_id]['points']['longitude'][current_idx[dataset_idx]] )\n",
    "    \n",
    "        geod = Geodesic.WGS84.Inverse( start_coord[0], start_coord[1], current_point[0], current_point[1] )\n",
    "        print(geod)\n",
    "    \n",
    "        if geod['s12'] < dist_thresh_m:\n",
    "        \n",
    "            #  Compute angle to new point\n",
    "            temp_angles.append( geod['azi1'])\n",
    "            print('Using Point from Dataset: {}. Dist: {}, Azimuth: {}'.format(dataset_id, geod['s12'], geod['azi1']))\n",
    "            current_route[dataset_id] = 0\n",
    "            matching_points.append( (dataset_id, 0) )\n",
    "        else:\n",
    "            current_route[dataset_id] = -1\n",
    "    avg_angle = mean_angle( temp_angles )\n",
    "    print('Azimuth: {}'.format(avg_angle))\n",
    "\n",
    "    #  Compute new point\n",
    "    geod = Geodesic.WGS84.Direct( current_point[0],\n",
    "                                  current_point[1],\n",
    "                                  avg_angle,\n",
    "                                  step_dist_m )\n",
    "    current_point = ( geod['lat2'], geod['lon2'] )\n",
    "    \n",
    "    #  Update Current Indices\n",
    "    for dataset_id in dataset_ids:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
